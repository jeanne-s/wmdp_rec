args:
  model_name: "meta-llama/Llama-3.2-1B-Instruct"
  unlearned_model: "models/meta-llama/Llama-3.2-1B-Instruct/02/model.pt"
  benchmarks:
    - wmdp
    - mmlu
  batch_size: 8
  limit: 100000
  trust_remote_code: True
  results_path: "benchmark_results/llama"
# 18.3GB VRAM
# 10min in A100 (including first time setup)