args:
  model_name: "HuggingFaceH4/zephyr-7b-beta"
  num_epochs: 1 
  num_batches: 150
  batch_size: 4
  forget_dataset_list:
    - "cyber-forget-corpus.jsonl"
    - "bio-forget-corpus.jsonl"
  retain_dataset_list:
    - "wikitext"
  learning_rate: 5e-5
  steering_coefficient: 6.5
  alpha: 1200.0
  forget_layer_id: 7
  optimizer_param_layer_id: 
    - 6
  update_layer_ids:
    - 5
    - 6
    - 7
  updated_model_path: "models/"
  seed: 42
# 44.8GB VRAM
# 2min in A100 (not including model download and cached portions)