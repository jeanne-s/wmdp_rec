args:
  model_name: "mistralai/Mixtral-8x7B-Instruct-v0.1"
  num_epochs: 1 
  num_batches: 400
  batch_size: 2
  forget_dataset_list:
    - "cyber-forget-corpus.jsonl"
    - "bio-forget-corpus.jsonl"
  retain_dataset_list:
    - "wikitext"
  learning_rate: 5e-5
  steering_coefficient: 300.0
  alpha: 1600.0
  forget_layer_id: 7
  optimizer_param_layer_id: 
    - 7
  update_layer_ids:
    - 5
    - 6
    - 7
  updated_model_path: "models/"
  seed: 42
# >80GB VRAM